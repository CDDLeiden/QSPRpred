{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment exported to qspr/models/environment.yml successfully!\n"
     ]
    }
   ],
   "source": [
    "# global settings\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "N_CPU = 12 # number of CPUs for parallel operations\n",
    "random_state = 42\n",
    "#random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = str(random_state)\n",
    "\n",
    "# logging settings\n",
    "from qsprpred.logs.utils import enable_file_logger, export_conda_environment\n",
    "logSettings = enable_file_logger(\n",
    "    log_folder = 'qspr/models',\n",
    "    filename = 'Modelling.log',\n",
    "    debug = False,\n",
    "    disable_existing_loggers = False\n",
    ")\n",
    "\n",
    "# save the environment to a yaml file\n",
    "export_conda_environment(\"qspr/models/environment.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already run this tutorial before? You can reload your data/models by running this cell and uncommenting the models/data you need.\n",
    "from qsprpred.data.data import QSPRDataset\n",
    "from qsprpred.models.interfaces import QSPRModel\n",
    "\n",
    "# For the regression part of the tutorial\n",
    "#dataset = QSPRDataset.fromFile('./qspr/data/tutorial_data_df.pkl')\n",
    "# model = QSPRModel.fromFile('./qspr/models/PLS_REG/PLS_REG_meta.json')\n",
    "\n",
    "# For the classification part of the tutorial\n",
    "# dataset = QSPRDataset.fromFile('./qspr/data/A2A_LIGANDS_df.pkl')\n",
    "# fitted_models = [QSPRModel.fromFile('./qspr/models/ExtraTreesClassifier/ExtraTreesClassifier_meta.json'),\n",
    "#                  QSPRModel.fromFile('./qspr/models/RandomForestClassifier/RandomForestClassifier_meta.json')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "\n",
    "QSPRPred package defines the `QSPRDataset` class, which is used to manage data and supply it to the models of interest (see [data_preparation](./data_preparation.ipynb) and [data_preparation_advanced](./data_preparation_advanced.ipynb)). We already assume you are familiar with these data structures, and we will use example data sets that are loaded automatically via the `datasets.py` module defined in the current folder. Feel free to examine this code to see how the data is loaded and preprocessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models - Regression\n",
    "\n",
    "Here, we will show how to train a simple single task regression model with QSPRPred.\n",
    "\n",
    "### Preparing the Data\n",
    "\n",
    "We will load the `Parkinsons` data set from `datasets.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples per target:\n",
      "GABAAalpha    6280\n",
      "NMDA          4073\n",
      "P41594        2730\n",
      "Q14416        1342\n",
      "Q13255         975\n",
      "Q14833         856\n",
      "Q14832         172\n",
      "O00222         153\n",
      "O15303         104\n",
      "Q14831          89\n",
      "Q14643          12\n",
      "Name: accession, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chichi148/Projects/QSPRpred/qsprpred/data/data.py:605: UserWarning: Existing data set found, but also found a data frame in store. Refusing to overwrite data. If you want to overwrite data in store, set overwrite=True.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>accession</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>GABAAalpha</th>\n",
       "      <th>NMDA</th>\n",
       "      <th>O00222</th>\n",
       "      <th>O15303</th>\n",
       "      <th>P41594</th>\n",
       "      <th>Q13255</th>\n",
       "      <th>Q14416</th>\n",
       "      <th>Q14643</th>\n",
       "      <th>Q14831</th>\n",
       "      <th>...</th>\n",
       "      <th>QSPRID</th>\n",
       "      <th>O00222_imputed</th>\n",
       "      <th>O15303_imputed</th>\n",
       "      <th>P41594_imputed</th>\n",
       "      <th>Q13255_imputed</th>\n",
       "      <th>Q14416_imputed</th>\n",
       "      <th>Q14831_imputed</th>\n",
       "      <th>Q14832_imputed</th>\n",
       "      <th>Q14833_imputed</th>\n",
       "      <th>Split_IsTrain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QSPRID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tutorial_data_98</th>\n",
       "      <td>C(#Cc1ncn2c1COc1ccccc1-2)c1ccccc1</td>\n",
       "      <td>5.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_98</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.975</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_99</th>\n",
       "      <td>C(#Cc1ncn2c1COc1ccccc1-2)c1cccnc1</td>\n",
       "      <td>6.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_99</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.500</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_2318</th>\n",
       "      <td>CN1Cc2c(C#Cc3ccccc3)ncn2-c2cccc(Cl)c2C1=O</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_2318</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>5.950</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_2319</th>\n",
       "      <td>CN1Cc2c(C#Cc3ccccc3)ncn2-c2ccc(F)cc2C1=O</td>\n",
       "      <td>8.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_2319</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.480</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4131</th>\n",
       "      <td>Cc1cccc(C#Cc2ncn3c2COc2ccccc2-3)c1</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4131</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.360</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4132</th>\n",
       "      <td>Cc1cc(C#Cc2ncn3c2COc2ccccc2-3)ccn1</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4132</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.900</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4141</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3cccc(S(C)(=O)=O)c3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4141</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.800</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4142</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3ccc(C#N)cc3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4142</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.120</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4143</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3ccc(F)cc3F)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4143</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.255</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4144</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3ccc(S(C)(=O)=O)cc3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4144</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.550</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4145</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3cccc(C#N)c3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4145</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.300</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4146</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3cccc(F)c3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4146</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.845</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4147</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3ccccc3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4147</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.720</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4303</th>\n",
       "      <td>Cc1ccc(C#Cc2ncn3c2COc2ccccc2-3)cc1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4303</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>5.400</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4552</th>\n",
       "      <td>Cc1ccccc1C#Cc1ncn2c1COc1ccccc1-2</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4552</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>5.675</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4795</th>\n",
       "      <td>Cc1cccc(C#Cc2ncn3c2COc2ccccc2-3)n1</td>\n",
       "      <td>5.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4795</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.790</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4806</th>\n",
       "      <td>Cc1nc(C#Cc2ccnc(Cl)c2)c(C)n1-c1ccc(F)cc1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4806</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.795</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4834</th>\n",
       "      <td>Cc1nc(C#Cc2ccccc2)c2n1-c1ccccc1OC2</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4834</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.750</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4842</th>\n",
       "      <td>Cc1nc(C#Cc2ccnc(Cl)c2)c(C)n1-c1ccc(F)cc1F</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4842</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.640</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_4843</th>\n",
       "      <td>Cc1nc(C#Cc2ccnc(Cl)c2)c(C)n1-c1ccc(OC(F)(F)F)cc1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_4843</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.850</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_5044</th>\n",
       "      <td>Cc1cc(C#Cc2cn(-c3ccc(F)cc3)c(C)n2)ccn1</td>\n",
       "      <td>5.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_5044</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>7.605</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial_data_5675</th>\n",
       "      <td>Fc1ccc2c(c1)-c1ncnn1Cc1c(C#Cc3ccccc3)ncn1-2</td>\n",
       "      <td>8.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tutorial_data_5675</td>\n",
       "      <td>5.070667</td>\n",
       "      <td>4.955192</td>\n",
       "      <td>6.280</td>\n",
       "      <td>6.286032</td>\n",
       "      <td>6.824711</td>\n",
       "      <td>4.752146</td>\n",
       "      <td>6.044017</td>\n",
       "      <td>5.833706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "accession                                                     SMILES  \\\n",
       "QSPRID                                                                 \n",
       "tutorial_data_98                   C(#Cc1ncn2c1COc1ccccc1-2)c1ccccc1   \n",
       "tutorial_data_99                   C(#Cc1ncn2c1COc1ccccc1-2)c1cccnc1   \n",
       "tutorial_data_2318         CN1Cc2c(C#Cc3ccccc3)ncn2-c2cccc(Cl)c2C1=O   \n",
       "tutorial_data_2319          CN1Cc2c(C#Cc3ccccc3)ncn2-c2ccc(F)cc2C1=O   \n",
       "tutorial_data_4131                Cc1cccc(C#Cc2ncn3c2COc2ccccc2-3)c1   \n",
       "tutorial_data_4132                Cc1cc(C#Cc2ncn3c2COc2ccccc2-3)ccn1   \n",
       "tutorial_data_4141   Cc1cc(C#Cc2cn(-c3cccc(S(C)(=O)=O)c3)c(C)n2)ccn1   \n",
       "tutorial_data_4142          Cc1cc(C#Cc2cn(-c3ccc(C#N)cc3)c(C)n2)ccn1   \n",
       "tutorial_data_4143           Cc1cc(C#Cc2cn(-c3ccc(F)cc3F)c(C)n2)ccn1   \n",
       "tutorial_data_4144   Cc1cc(C#Cc2cn(-c3ccc(S(C)(=O)=O)cc3)c(C)n2)ccn1   \n",
       "tutorial_data_4145          Cc1cc(C#Cc2cn(-c3cccc(C#N)c3)c(C)n2)ccn1   \n",
       "tutorial_data_4146            Cc1cc(C#Cc2cn(-c3cccc(F)c3)c(C)n2)ccn1   \n",
       "tutorial_data_4147               Cc1cc(C#Cc2cn(-c3ccccc3)c(C)n2)ccn1   \n",
       "tutorial_data_4303                Cc1ccc(C#Cc2ncn3c2COc2ccccc2-3)cc1   \n",
       "tutorial_data_4552                  Cc1ccccc1C#Cc1ncn2c1COc1ccccc1-2   \n",
       "tutorial_data_4795                Cc1cccc(C#Cc2ncn3c2COc2ccccc2-3)n1   \n",
       "tutorial_data_4806          Cc1nc(C#Cc2ccnc(Cl)c2)c(C)n1-c1ccc(F)cc1   \n",
       "tutorial_data_4834                Cc1nc(C#Cc2ccccc2)c2n1-c1ccccc1OC2   \n",
       "tutorial_data_4842         Cc1nc(C#Cc2ccnc(Cl)c2)c(C)n1-c1ccc(F)cc1F   \n",
       "tutorial_data_4843  Cc1nc(C#Cc2ccnc(Cl)c2)c(C)n1-c1ccc(OC(F)(F)F)cc1   \n",
       "tutorial_data_5044            Cc1cc(C#Cc2cn(-c3ccc(F)cc3)c(C)n2)ccn1   \n",
       "tutorial_data_5675       Fc1ccc2c(c1)-c1ncnn1Cc1c(C#Cc3ccccc3)ncn1-2   \n",
       "\n",
       "accession           GABAAalpha  NMDA  O00222  O15303  P41594  Q13255  Q14416  \\\n",
       "QSPRID                                                                         \n",
       "tutorial_data_98          5.92   NaN     NaN     NaN   6.975     NaN     NaN   \n",
       "tutorial_data_99          6.35   NaN     NaN     NaN   6.500     NaN     NaN   \n",
       "tutorial_data_2318        9.00   NaN     NaN     NaN   5.950     NaN     NaN   \n",
       "tutorial_data_2319        8.40   NaN     NaN     NaN   6.480     NaN     NaN   \n",
       "tutorial_data_4131        6.47   NaN     NaN     NaN   7.360     NaN     NaN   \n",
       "tutorial_data_4132        6.47   NaN     NaN     NaN   7.900     NaN     NaN   \n",
       "tutorial_data_4141        5.50   NaN     NaN     NaN   6.800     NaN     NaN   \n",
       "tutorial_data_4142        5.50   NaN     NaN     NaN   7.120     NaN     NaN   \n",
       "tutorial_data_4143        5.50   NaN     NaN     NaN   7.255     NaN     NaN   \n",
       "tutorial_data_4144        5.50   NaN     NaN     NaN   6.550     NaN     NaN   \n",
       "tutorial_data_4145        5.50   NaN     NaN     NaN   7.300     NaN     NaN   \n",
       "tutorial_data_4146        5.50   NaN     NaN     NaN   7.845     NaN     NaN   \n",
       "tutorial_data_4147        5.50   NaN     NaN     NaN   7.720     NaN     NaN   \n",
       "tutorial_data_4303        5.50   NaN     NaN     NaN   5.400     NaN     NaN   \n",
       "tutorial_data_4552        5.50   NaN     NaN     NaN   5.675     NaN     NaN   \n",
       "tutorial_data_4795        5.87   NaN     NaN     NaN   6.790     NaN     NaN   \n",
       "tutorial_data_4806        5.50   NaN     NaN     NaN   7.795     NaN     NaN   \n",
       "tutorial_data_4834        5.50   NaN     NaN     NaN   7.750     NaN     NaN   \n",
       "tutorial_data_4842        5.50   NaN     NaN     NaN   7.640     NaN     NaN   \n",
       "tutorial_data_4843        5.50   NaN     NaN     NaN   7.850     NaN     NaN   \n",
       "tutorial_data_5044        5.50   NaN     NaN     NaN   7.605     NaN     NaN   \n",
       "tutorial_data_5675        8.22   NaN     NaN     NaN   6.280     NaN     NaN   \n",
       "\n",
       "accession           Q14643  Q14831  ...              QSPRID  O00222_imputed  \\\n",
       "QSPRID                              ...                                       \n",
       "tutorial_data_98       NaN     NaN  ...    tutorial_data_98        5.070667   \n",
       "tutorial_data_99       NaN     NaN  ...    tutorial_data_99        5.070667   \n",
       "tutorial_data_2318     NaN     NaN  ...  tutorial_data_2318        5.070667   \n",
       "tutorial_data_2319     NaN     NaN  ...  tutorial_data_2319        5.070667   \n",
       "tutorial_data_4131     NaN     NaN  ...  tutorial_data_4131        5.070667   \n",
       "tutorial_data_4132     NaN     NaN  ...  tutorial_data_4132        5.070667   \n",
       "tutorial_data_4141     NaN     NaN  ...  tutorial_data_4141        5.070667   \n",
       "tutorial_data_4142     NaN     NaN  ...  tutorial_data_4142        5.070667   \n",
       "tutorial_data_4143     NaN     NaN  ...  tutorial_data_4143        5.070667   \n",
       "tutorial_data_4144     NaN     NaN  ...  tutorial_data_4144        5.070667   \n",
       "tutorial_data_4145     NaN     NaN  ...  tutorial_data_4145        5.070667   \n",
       "tutorial_data_4146     NaN     NaN  ...  tutorial_data_4146        5.070667   \n",
       "tutorial_data_4147     NaN     NaN  ...  tutorial_data_4147        5.070667   \n",
       "tutorial_data_4303     NaN     NaN  ...  tutorial_data_4303        5.070667   \n",
       "tutorial_data_4552     NaN     NaN  ...  tutorial_data_4552        5.070667   \n",
       "tutorial_data_4795     NaN     NaN  ...  tutorial_data_4795        5.070667   \n",
       "tutorial_data_4806     NaN     NaN  ...  tutorial_data_4806        5.070667   \n",
       "tutorial_data_4834     NaN     NaN  ...  tutorial_data_4834        5.070667   \n",
       "tutorial_data_4842     NaN     NaN  ...  tutorial_data_4842        5.070667   \n",
       "tutorial_data_4843     NaN     NaN  ...  tutorial_data_4843        5.070667   \n",
       "tutorial_data_5044     NaN     NaN  ...  tutorial_data_5044        5.070667   \n",
       "tutorial_data_5675     NaN     NaN  ...  tutorial_data_5675        5.070667   \n",
       "\n",
       "accession          O15303_imputed  P41594_imputed  Q13255_imputed  \\\n",
       "QSPRID                                                              \n",
       "tutorial_data_98         4.955192           6.975        6.286032   \n",
       "tutorial_data_99         4.955192           6.500        6.286032   \n",
       "tutorial_data_2318       4.955192           5.950        6.286032   \n",
       "tutorial_data_2319       4.955192           6.480        6.286032   \n",
       "tutorial_data_4131       4.955192           7.360        6.286032   \n",
       "tutorial_data_4132       4.955192           7.900        6.286032   \n",
       "tutorial_data_4141       4.955192           6.800        6.286032   \n",
       "tutorial_data_4142       4.955192           7.120        6.286032   \n",
       "tutorial_data_4143       4.955192           7.255        6.286032   \n",
       "tutorial_data_4144       4.955192           6.550        6.286032   \n",
       "tutorial_data_4145       4.955192           7.300        6.286032   \n",
       "tutorial_data_4146       4.955192           7.845        6.286032   \n",
       "tutorial_data_4147       4.955192           7.720        6.286032   \n",
       "tutorial_data_4303       4.955192           5.400        6.286032   \n",
       "tutorial_data_4552       4.955192           5.675        6.286032   \n",
       "tutorial_data_4795       4.955192           6.790        6.286032   \n",
       "tutorial_data_4806       4.955192           7.795        6.286032   \n",
       "tutorial_data_4834       4.955192           7.750        6.286032   \n",
       "tutorial_data_4842       4.955192           7.640        6.286032   \n",
       "tutorial_data_4843       4.955192           7.850        6.286032   \n",
       "tutorial_data_5044       4.955192           7.605        6.286032   \n",
       "tutorial_data_5675       4.955192           6.280        6.286032   \n",
       "\n",
       "accession           Q14416_imputed  Q14831_imputed  Q14832_imputed  \\\n",
       "QSPRID                                                               \n",
       "tutorial_data_98          6.824711        4.752146        6.044017   \n",
       "tutorial_data_99          6.824711        4.752146        6.044017   \n",
       "tutorial_data_2318        6.824711        4.752146        6.044017   \n",
       "tutorial_data_2319        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4131        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4132        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4141        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4142        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4143        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4144        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4145        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4146        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4147        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4303        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4552        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4795        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4806        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4834        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4842        6.824711        4.752146        6.044017   \n",
       "tutorial_data_4843        6.824711        4.752146        6.044017   \n",
       "tutorial_data_5044        6.824711        4.752146        6.044017   \n",
       "tutorial_data_5675        6.824711        4.752146        6.044017   \n",
       "\n",
       "accession           Q14833_imputed  Split_IsTrain  \n",
       "QSPRID                                             \n",
       "tutorial_data_98          5.833706          False  \n",
       "tutorial_data_99          5.833706          False  \n",
       "tutorial_data_2318        5.833706           True  \n",
       "tutorial_data_2319        5.833706           True  \n",
       "tutorial_data_4131        5.833706           True  \n",
       "tutorial_data_4132        5.833706           True  \n",
       "tutorial_data_4141        5.833706           True  \n",
       "tutorial_data_4142        5.833706           True  \n",
       "tutorial_data_4143        5.833706          False  \n",
       "tutorial_data_4144        5.833706           True  \n",
       "tutorial_data_4145        5.833706           True  \n",
       "tutorial_data_4146        5.833706           True  \n",
       "tutorial_data_4147        5.833706           True  \n",
       "tutorial_data_4303        5.833706          False  \n",
       "tutorial_data_4552        5.833706           True  \n",
       "tutorial_data_4795        5.833706          False  \n",
       "tutorial_data_4806        5.833706           True  \n",
       "tutorial_data_4834        5.833706           True  \n",
       "tutorial_data_4842        5.833706           True  \n",
       "tutorial_data_4843        5.833706           True  \n",
       "tutorial_data_5044        5.833706           True  \n",
       "tutorial_data_5675        5.833706           True  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Parkinsons\n",
    "\n",
    "dataset = Parkinsons(random_state=random_state)\n",
    "dataset.getDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a regression model for the GABA(A) receptor subunit alpha (GABAAalpha).\n",
    "Therefore, we initialize our QSPRdataset as regression for \"GABAAalpha\".\n",
    "After this we need to do some processing of the data.\n",
    "We need to calculate compound features, split our dataset into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Molecular descriptors already exist in tutorial_data. Use `recalculate=True` to overwrite them.\n",
      "Missing values filled with nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples train set: 17\n",
      "Number of samples test set: 5\n"
     ]
    }
   ],
   "source": [
    "from qsprpred.data.utils.descriptorsets import FingerprintSet\n",
    "from qsprpred.data.utils.descriptorcalculator import MoleculeDescriptorsCalculator\n",
    "from sklearn.preprocessing import StandardScaler as Scaler\n",
    "from qsprpred.data.utils.datasplitters import RandomSplit\n",
    "\n",
    "# Calculate MorganFP and physicochemical properties\n",
    "feature_calculator = MoleculeDescriptorsCalculator(desc_sets = [FingerprintSet(fingerprint_type=\"MorganFP\", radius=3, nBits=2048)])\n",
    "\n",
    "# Do a random split for creating the train (85%) and test set (15%)\n",
    "rand_split = RandomSplit(test_fraction=0.2, dataset=dataset)\n",
    "\n",
    "# calculate compound features and split dataset into train and test\n",
    "dataset.prepareDataset(\n",
    "    split=rand_split,\n",
    "    feature_calculators=[feature_calculator],\n",
    "    feature_standardizer=Scaler()\n",
    ")\n",
    "\n",
    "print(f\"Number of samples train set: {len(dataset.y)}\")\n",
    "print(f\"Number of samples test set: {len(dataset.y_ind)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prepareDataset` function is shorthand method that can be used to perform multiple steps at once, but these steps can also be performed individually. For example, we can calculate the features and split the dataset separately by several calls to various methods of the `QSPRDataset` class. The following code should be equivalent to the previous one:\n",
    "\n",
    "```python\n",
    "\n",
    "# Calculate MorganFP and physicochemical properties\n",
    "feature_calculator = MoleculeDescriptorsCalculator(desc_sets = [FingerprintSet(fingerprint_type=\"MorganFP\", radius=3, nBits=2048)])\n",
    "dataset.addDescriptors(feature_calculator, featurize=False)\n",
    "dataset.fillMissingValues()\n",
    "dataset.splitDataset(rand_split)\n",
    "dataset.setFeatureStandardizer(Scaler())\n",
    "self.featurizeSplits()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the dataset for later\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "After preparing our dataset, we will train a QSPR regression model.\n",
    "In this tutorial we will train a XGBoost model as it generally performs well, but there are other model types\n",
    "available. Most machine learning models have tunable hyperparameters (for example depth & learning rate), as some hyperparameter combinations will lead to better performance on a task we perform hyperparameter optimization (in which different combinations are tested and evaluated on a subset of the training data). After finding good hyperparameters a model will be trained on the training data & evaluated on the test data. In addition to this the final model will be trained on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "At the moment n_jobs>1 not available for bayes optimization, n_jobs set to 1.\n",
      "[I 2023-08-10 19:16:38,328] A new study created in memory with name: no-name-c175329c-21f6-4c8c-b5ee-2c61f6537660\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 12\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 12\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 13\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 13\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 13\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "[I 2023-08-10 19:16:38,413] Trial 0 finished with value: 0.6658313393644304 and parameters: {'n_components': 23, 'scale': True}. Best is trial 0 with value: 0.6658313393644304.\n",
      "[I 2023-08-10 19:16:38,475] Trial 1 finished with value: 0.6654643047122633 and parameters: {'n_components': 5, 'scale': True}. Best is trial 0 with value: 0.6658313393644304.\n",
      "[I 2023-08-10 19:16:38,539] Trial 2 finished with value: 0.6640508933548628 and parameters: {'n_components': 4, 'scale': True}. Best is trial 0 with value: 0.6658313393644304.\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 12\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 12\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 13\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 13\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "/home/chichi148/anaconda3/lib/python3.10/site-packages/sklearn/cross_decomposition/_pls.py:300: UserWarning: Y residual is constant at iteration 13\n",
      "  warnings.warn(f\"Y residual is constant at iteration {k}\")\n",
      "[I 2023-08-10 19:16:38,611] Trial 3 finished with value: 0.6658313359530796 and parameters: {'n_components': 18, 'scale': False}. Best is trial 0 with value: 0.6658313393644304.\n",
      "[I 2023-08-10 19:16:38,672] Trial 4 finished with value: 0.6640508933548628 and parameters: {'n_components': 4, 'scale': True}. Best is trial 0 with value: 0.6658313393644304.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'qspr/models/PLS_REG/PLS_REG_meta.json'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qsprpred.models.models import QSPRsklearn\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from qsprpred.models.hyperparam_optimization import OptunaOptimization\n",
    "from qsprpred.models.assessment_methods import CrossValAssessor, TestSetAssessor\n",
    "from qsprpred.models.metrics import SklearnMetric\n",
    "\n",
    "# This is an SKlearn model, so we will initialize it with the QSPRsklearn class\n",
    "model = QSPRsklearn(base_dir = 'qspr/models/', data=dataset, alg = PLSRegression, name='PLS_REG')\n",
    "\n",
    "# We will first optimize the hyperparameters (n_components and scale) through bayes optimization\n",
    "# the best hyperparameter combination will be saved in PLS_REG_GABAAalpha_params.json\n",
    "score_func = SklearnMetric.getDefaultMetric(model.task)\n",
    "search_space_bs = {\"n_components\": [\"int\", 1, 30], \"scale\": [\"categorical\", [True, False]]}\n",
    "bayesoptimizer = OptunaOptimization(scoring = score_func, param_grid=search_space_bs,\n",
    "                                    n_trials=5, n_jobs=4)\n",
    "best_params = bayesoptimizer.optimize(model)\n",
    "\n",
    "#Then we will evaluate the performance of the best model using the independent test set\n",
    "CrossValAssessor()(model)\n",
    "TestSetAssessor()(model)\n",
    "\n",
    "# Finally, we need to fit the model on the complete dataset if we want to use it further\n",
    "# model is saved under qsprmodels/PLS_REG_GABAAalpha.pkg\n",
    "model.fitAttached()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to sve the model first\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results of our model on the test set we can see that it is performing reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from qsprpred.plotting.regression import CorrelationPlot\n",
    "from qsprpred.models.interfaces import QSPRModel\n",
    "\n",
    "# give path to saved metadata of the model and load it\n",
    "#metadata_path = './qspr/models/PLS_GABAAalpha_REGRESSION/PLS_GABAAalpha_REGRESSION_meta.json'\n",
    "#model = QSPRModel.fromFile(metadata_path)\n",
    "model\n",
    "plt = CorrelationPlot([model])\n",
    "axes, summary = plt.make(save=False, property_name='GABAAalpha')\n",
    "axes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the plot also generates a summary with the displayed metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models - Classification\n",
    "\n",
    "In this part of the tutorial, we show how to train a simple single task classification model with QSPRPred.\n",
    "\n",
    "### Preparing the Data\n",
    "\n",
    "We will repeat the same steps as with the regression model, but this time with classification data loaded from `datasets.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.data.utils.datasplitters import ScaffoldSplit\n",
    "from qsprpred.data.utils.descriptorcalculator import MoleculeDescriptorsCalculator\n",
    "from qsprpred.data.utils.descriptorsets import FingerprintSet\n",
    "from qsprpred.data.utils.featurefilters import LowVarianceFilter, HighCorrelationFilter\n",
    "from qsprpred.data.utils.scaffolds import Murcko\n",
    "from datasets import A2AR\n",
    "\n",
    "# intialize the dataset\n",
    "dataset = A2AR(random_state=random_state)\n",
    "\n",
    "# Calculate MorganFP and physicochemical properties\n",
    "feature_calculator = MoleculeDescriptorsCalculator(desc_sets = [FingerprintSet(fingerprint_type=\"MorganFP\", radius=3, nBits=2048)])\n",
    "\n",
    "# Split on scaffolds\n",
    "split = ScaffoldSplit(dataset=dataset, scaffold=Murcko(), test_fraction=0.2)\n",
    "\n",
    "# Remove features that have a low variance (<0.05) in the trainingset\n",
    "lv = LowVarianceFilter(0.05)\n",
    "\n",
    "# Remove features that have a high correlation (>0.9) in the trainingset\n",
    "hc = HighCorrelationFilter(0.8)\n",
    "\n",
    "dataset.prepareDataset(\n",
    "    split=split,\n",
    "    feature_calculators=[feature_calculator],\n",
    "    feature_filters=[lv, hc]\n",
    ")\n",
    "\n",
    "# save the data set if you do not want to recalculate descriptors\n",
    "dataset.save()\n",
    "\n",
    "print(f\"Number of samples train set: {len(dataset.y)}\")\n",
    "print(f\"Number of samples test set: {len(dataset.y_ind)}, {len(dataset.y_ind) / len(dataset.df) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataset again so that we do not have to recalculate anything later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the training part basically works the same way as with regression, but to mix things up we build two models at once here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from qsprpred.models.models import QSPRsklearn\n",
    "from qsprpred.models.hyperparam_optimization import GridSearchOptimization\n",
    "from qsprpred.models.assessment_methods import CrossValAssessor, TestSetAssessor\n",
    "from qsprpred.models.metrics import SklearnMetric\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [50, 200],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "    \"n_jobs\": [1]\n",
    "}\n",
    "\n",
    "\n",
    "fitted_models = []\n",
    "for model in [ExtraTreesClassifier, RandomForestClassifier]:\n",
    "    model = QSPRsklearn(\n",
    "        base_dir='qspr/models/',\n",
    "        data=dataset, \n",
    "        alg = model,\n",
    "        name=model.__name__,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    score_func = SklearnMetric.getDefaultMetric(model.task)\n",
    "    gridsearcher = GridSearchOptimization(scoring = score_func, param_grid=params)\n",
    "    best_params = gridsearcher.optimize(model)\n",
    "\n",
    "    CrossValAssessor()(model)\n",
    "    TestSetAssessor()(model)\n",
    "    model.fitAttached()\n",
    "    \n",
    "    fitted_models.append(model)\n",
    "\n",
    "fitted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.plotting.classification import ROCPlot\n",
    "\n",
    "plot = ROCPlot(fitted_models)\n",
    "plot.make(save=True, show=True, property_name=\"pchembl_value_Median_class\", validation=\"cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.make(save = True, show=True, property_name=\"pchembl_value_Median_class\", validation=\"ind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.plotting.classification import MetricsPlot\n",
    "\n",
    "plot = MetricsPlot(fitted_models)\n",
    "figs, summary = plot.make(save=True, show=True, property_name=\"pchembl_value_Median_class\", out_dir=\"qspr/models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the summary contains the data frame with the metrics used to create the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask Regression Model\n",
    "Until now, the examples have show models that predict one property (single task). In addition to this we can also make multitask models that are trained with multiple different properties simultaneously. This can, for example, be a model that predicts the bioactivity on two or more proteins. Below, we will build a multitask model for 8 different human mGLU receptors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data on the mGLU receptors can also be found in the `Parkinsons` dataset. Here we specify that singletask is False, so that all the targets are set as properties to predict (see `datasets.py` for the exact code, note the now necessary imputation step):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Parkinsons\n",
    "\n",
    "dataset = Parkinsons(singletask=False, random_state=random_state)\n",
    "dataset.targetProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataset.getDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature calculation and dataset preparation is the same as for single task models. During splitting compounds are assigned to the training or test set (not individual datapoints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsprpred.data.utils.descriptorsets import FingerprintSet\n",
    "from qsprpred.data.utils.descriptorcalculator import MoleculeDescriptorsCalculator\n",
    "from sklearn.preprocessing import StandardScaler as Scaler\n",
    "from qsprpred.data.utils.datasplitters import RandomSplit\n",
    "\n",
    "# Calculate MorganFP and physicochemical properties\n",
    "feature_calculator = MoleculeDescriptorsCalculator(desc_sets = [FingerprintSet(fingerprint_type=\"MorganFP\", radius=3, nBits=2048)])\n",
    "\n",
    "# Do a random split for creating the train (85%) and test set (15%)\n",
    "rand_split = RandomSplit(test_fraction=0.2, dataset=dataset)\n",
    "\n",
    "# calculate compound features and split dataset into train and test\n",
    "dataset.prepareDataset(\n",
    "    split=rand_split,\n",
    "    feature_calculators=[feature_calculator],\n",
    "    feature_standardizer=Scaler()\n",
    ")\n",
    "\n",
    "print(f\"Number of samples train set: {len(dataset.y)}\")\n",
    "print(f\"Number of samples test set: {len(dataset.y_ind)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset again to avoid recalculation later if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "We use a KNN model because it is relatively fast and the previously shown PLS does not work with multiple-tasks. Because hyperparameter optimization works the same as for single task models, we skip this step here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qspr/models/KNN_REG_MT/KNN_REG_MT_meta.json'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qsprpred.models.models import QSPRsklearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from qsprpred.models.assessment_methods import CrossValAssessor, TestSetAssessor\n",
    "\n",
    "# This is an SKlearn model, so we will initialize it with the QSPRsklearn class\n",
    "model = QSPRsklearn(base_dir = 'qspr/models/', data=dataset, alg = KNeighborsRegressor, name='KNN_REG_MT')\n",
    "\n",
    "CrossValAssessor()(model)\n",
    "TestSetAssessor()(model)\n",
    "\n",
    "# Finally, we need to fit the model on the complete dataset if we want to use it further\n",
    "model.fitAttached()\n",
    "\n",
    "# and save the model\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "Here we show how to calculate the metrics that are compatible with multitask model results using an `SklearnMetric` object. Currently, imputed values are included in this analysis, the option to remove these from the analysis will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(5, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m SklearnMetric\u001b[38;5;241m.\u001b[39mmultiTaskRegressionMetrics:\n\u001b[1;32m     19\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m SklearnMetric\u001b[38;5;241m.\u001b[39mgetMetric(metric)\n\u001b[0;32m---> 20\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mylabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mypred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     summary[metric]\u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m     23\u001b[0m summary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/Projects/QSPRpred/qsprpred/models/metrics.py:269\u001b[0m, in \u001b[0;36mSklearnMetric.__call__\u001b[0;34m(self, y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# if single class classification, convert to 1d array\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/QSPRpred/qsprpred/models/metrics.py:339\u001b[0m, in \u001b[0;36mSklearnMetric.scorerFunc\u001b[0;34m(scorer, y_true, y_pred)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"Return the scoring function of a sklearn scorer.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# From https://stackoverflow.com/questions/63943410/getting-a-scoring-function-by-name-in-scikit-learn\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scorer\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:762\u001b[0m, in \u001b[0;36mexplained_variance_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplained_variance_score\u001b[39m(\n\u001b[1;32m    660\u001b[0m     y_true,\n\u001b[1;32m    661\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    666\u001b[0m ):\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;124;03m\"\"\"Explained variance regression score function.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0, lower values are worse.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    -inf\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    767\u001b[0m     y_diff_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(y_true \u001b[38;5;241m-\u001b[39m y_pred, weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 101\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[0;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[1;32m    944\u001b[0m         )\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(5, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "from qsprpred.models.metrics import SklearnMetric\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# get independent test set\n",
    "df = pd.read_table(\"qspr/models/KNN_REG_MT/KNN_REG_MT.ind.tsv\")\n",
    "\n",
    "# column names containing original labels or predictions for the tasks\n",
    "label_names = [i for i in list(df.columns.values) if \"imputed_Label\" in i] \n",
    "pred_names = [i for i in list(df.columns.values) if \"imputed_Prediction\" in i]\n",
    " \n",
    "# turn into np array\n",
    "ylabel = df[label_names].to_numpy()\n",
    "ypred = df[pred_names].to_numpy()\n",
    "\n",
    "# get metrics\n",
    "summary = {}\n",
    "for metric in SklearnMetric.multiTaskRegressionMetrics:\n",
    "    scorer = SklearnMetric.getMetric(metric)\n",
    "    score = scorer(ylabel, ypred)\n",
    "    summary[metric]= score\n",
    "\n",
    "summary[\"ModelName\"] = model.name\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we plot the predicted pchembl values against the experimental results, to visualize model performance. This is not yet integrate in the QSPRPred plotting functions so the code is more extensive than for the single task models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "property_name = \"pChEMBL\"\n",
    "\n",
    "my_cmap = [\"#12517B\", \"#88002A\"]\n",
    "\n",
    "plt.figure(figsize=(5, 7))\n",
    "cate = [\"qspr/models/KNN_REG_MT/KNN_REG_MT.cv.tsv\", \"qspr/models/KNN_REG_MT/KNN_REG_MT.ind.tsv\"]\n",
    "cate_names = [\"cv\", \"ind\"]\n",
    "ret_axes = []\n",
    "summary = {\"ModelName\": [], \"R2\": [], \"RMSE\": [], \"Set\": []}\n",
    "\n",
    "\n",
    "for m, mymodel in enumerate([model]):\n",
    "    min_val = 0\n",
    "    max_val = 10\n",
    "    for j, cate_name in enumerate(['Cross Validation', 'Independent Test']):\n",
    "        ax = plt.subplot(2, len([model]), m + j + 1)\n",
    "        ret_axes.append(ax)\n",
    "        #todo create subplot show can show both plots\n",
    "        df = pd.read_table(cate[j])\n",
    "        # column names containing original labels or predictions for the tasks\n",
    "        label_names = [i for i in list(df.columns.values) if \"imputed_Label\" in i]  #df[f\"{property_name}_imputed_Label\"]\n",
    "        labels = [i.replace(\"_imputed_Label\", '') for i in label_names]\n",
    "        pred_names = [i for i in list(df.columns.values) if \"imputed_Prediction\" in i] #df[f\"{property_name}_imputed_Prediction\"]\n",
    "\n",
    "        # # create mask with True if original value, False where no value in original  dataset\n",
    "        # #TODO currently does not work because do not have df with cv / ind, nee\n",
    "        # array = df_that_does_not_exist_yet[labels].to_numpy()\n",
    "        # mask = ~np.isnan(array)\n",
    "        \n",
    "        # turn ylabel and ypred into np array\n",
    "        ylabel = df[label_names].to_numpy()\n",
    "        c = np.zeros(ylabel.shape)\n",
    "        for k in range(c.shape[1]):\n",
    "            c[:, k] = k\n",
    "        c.flatten()\n",
    "        \n",
    "        ylabel = ylabel.flatten()\n",
    "        ypred = df[pred_names].to_numpy().flatten()\n",
    "        # mask = mask.flatten()\n",
    "\n",
    "        # # no markers for inputed values\n",
    "        # area = np.full(mask.shape, 5)\n",
    "        # area1 = np.ma.masked_where(mask, area)\n",
    "        # scatter = plt.scatter(\n",
    "        #     ylabel,\n",
    "        #     ypred,\n",
    "        #     s=area1,\n",
    "        #     c=c)\n",
    "\n",
    "        scatter = plt.scatter(\n",
    "            ylabel,\n",
    "            ypred,\n",
    "            s=5,\n",
    "            c=c)\n",
    "        coef = metrics.r2_score(ylabel, ypred)\n",
    "        rmse = metrics.mean_squared_error(\n",
    "            ylabel, ypred,\n",
    "            squared=False)\n",
    "        summary[\"R2\"].append(coef)\n",
    "        summary[\"RMSE\"].append(rmse)\n",
    "        summary[\"Set\"].append(cate_names[j])\n",
    "        summary[\"ModelName\"].append(model.name)\n",
    "\n",
    "        plt.title(f'{model} {cate_name}')\n",
    "        plt.xlabel(f\"Experimental {property_name}\")\n",
    "        plt.ylabel(f\"Predicted {property_name}\")\n",
    "        min_val_now = math.floor(\n",
    "            min(np.concatenate((ylabel, ypred))))\n",
    "        max_val_now = math.ceil(\n",
    "            max(np.concatenate((ylabel, ypred))))\n",
    "        if min_val_now < min_val:\n",
    "            min_val = min_val_now\n",
    "        if max_val_now > max_val:\n",
    "            max_val = max_val_now\n",
    "        pad = (max_val - min_val) * 0.1\n",
    "        plt.plot(\n",
    "            [min_val - pad, max_val + pad],\n",
    "            [min_val - pad, max_val + pad],\n",
    "            lw=2, linestyle='--', color='black')\n",
    "\n",
    "        handles, _ = scatter.legend_elements()\n",
    "\n",
    "        plt.legend(handles, labels, title=\"Tasks\", loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "94705a58f524c087a931a9ce6f495e1949dee73c0ce5184db4e9163355ae55e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
