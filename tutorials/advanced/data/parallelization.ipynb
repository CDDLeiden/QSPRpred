{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fedcee856268b35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Code Parallelization\n",
    "\n",
    "QSPRpred is also helpful to run parallel operations on data. It tries to take the headache out of parallelization by\n",
    "providing a simple interface to run operations on data in parallel. In this tutorial, we will show how to use the\n",
    "these features.\n",
    "\n",
    "## Data Set\n",
    "\n",
    "We will borrow the multitask data set from the [associated tutorial](../modelling/multi_task_modelling.ipynb) since it contains a larger number of molecules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:47.128460764Z",
     "start_time": "2024-01-16T16:30:44.687611093Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57590/2289215288.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6797"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from qsprpred.data import MoleculeTable\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('../../tutorial_data/AR_LIGANDS.tsv', sep='\\t')\n",
    "df = df.pivot(index=\"SMILES\", columns=\"accession\", values=\"pchembl_value_Mean\")\n",
    "df.columns.name = None\n",
    "df.reset_index(inplace=True)\n",
    "mt = MoleculeTable(name=\"ParallelizationExample\", df=df)\n",
    "len(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ffda3a4b8202f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setting `nJobs` and `chunkSize`\n",
    "\n",
    "QSPRpred supports parallelization of code by chunking the data set into smaller\n",
    "pieces and running the code on each chunk in parallel. This is done by setting\n",
    "the `nJobs` and `chunkSize` properties of the `MoleculeTable` object. The\n",
    "`nJobs` property specifies the number of parallel jobs to run. The `chunkSize`\n",
    "property specifies the number of molecules to process in each job. \n",
    "\n",
    "The `chunkSize` property is automatically calculated based on the number of jobs, but\n",
    "in some cases it may be useful to set it manually. For example, if the code\n",
    "being run in parallel is very fast, it may be useful to increase the chunk size\n",
    "to reduce the overhead of parallelization. On the other hand, if the code being\n",
    "run in parallel is very slow, it may be useful to decrease the chunk size to\n",
    "reduce the amount of time spent waiting for the slowest job to finish. \n",
    "\n",
    "In addition, the\n",
    "`chunkSize` property also affects the memory usage of the parallelization. If\n",
    "the code being run in parallel is very memory intensive, it may be useful to\n",
    "decrease the chunk size to reduce the memory usage of the parallel processes \n",
    "by running on smaller batches of data.\n",
    "\n",
    "We will now illustrate a few different scenarios. First, we will run a simple\n",
    "descriptor calculation in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fb8189f4bd2cf62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:51.361058064Z",
     "start_time": "2024-01-16T16:30:47.131517756Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running and timing descriptor calculation: MorganFP\n",
      "Time it took: 4.8388890370115405\n"
     ]
    }
   ],
   "source": [
    "from qsprpred.data.descriptors.sets import DescriptorSet\n",
    "from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "from qsprpred.utils.stopwatch import StopWatch\n",
    "\n",
    "\n",
    "def time_desc_calc(data: MoleculeTable, desc_set: DescriptorSet):\n",
    "    \"\"\"A simple function to time descriptor calculation on a data table.\n",
    "    \n",
    "    Args:\n",
    "        data: The data table to calculate descriptors on.\n",
    "        desc_set: The descriptor set to calculate.\n",
    "    \"\"\"\n",
    "    if data.hasDescriptors([desc_set])[0]:\n",
    "        print(f\"Removing old descriptors: {desc_set}\")\n",
    "        data.dropDescriptors([desc_set])\n",
    "    print(f\"Running and timing descriptor calculation: {desc_set}\")\n",
    "    watch = StopWatch()\n",
    "    data.addDescriptors([desc_set])\n",
    "    watch.stop()\n",
    "\n",
    "\n",
    "time_desc_calc(mt, MorganFP(3, 2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357f12c0516b989",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This calculation is done on one CPU by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44f3b39aa13bde1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:51.368391209Z",
     "start_time": "2024-01-16T16:30:51.363595085Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.nJobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e51a9829413df0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and the whole data set supplied as one chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a597d9ec3e477d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:51.372183338Z",
     "start_time": "2024-01-16T16:30:51.367032511Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6797"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.chunkSize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c75dc19273bed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can now try running this calculation in parallel on 2 CPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a15d314e606079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:51.379969255Z",
     "start_time": "2024-01-16T16:30:51.375227876Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt.nJobs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6ee9045cc5f12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The chunk size will automatically be adjusted to 25% of the data set size so that each portion of the data set is processed on a separate CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de8694100c644d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:51.411732902Z",
     "start_time": "2024-01-16T16:30:51.378238063Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.chunkSize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21998b62ee78bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see how this affects the time taken to run the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99a9131bc8db3e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:30:53.084658845Z",
     "start_time": "2024-01-16T16:30:51.383586975Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old descriptors: MorganFP\n",
      "Running and timing descriptor calculation: MorganFP\n",
      "Time it took: 1.6204400029964745\n"
     ]
    }
   ],
   "source": [
    "time_desc_calc(mt, MorganFP(3, 2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5243c149010a23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This was faster, but not by a factor of 4. This is because there is some overhead associated with parallelization and the calculation of fingerprints is very fast by itself so the overhead affects our runtime more. In such cases, be careful about setting the chunk size manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5b1bdf9bdb5db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.073558913Z",
     "start_time": "2024-01-16T16:30:53.083216365Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old descriptors: MorganFP\n",
      "Running and timing descriptor calculation: MorganFP\n",
      "Time it took: 7.653213223995408\n"
     ]
    }
   ],
   "source": [
    "mt.chunkSize = 10\n",
    "time_desc_calc(mt, MorganFP(3, 2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdc32aa83072e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This was slower than even the single CPU calculation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2367dd655da9c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Custom Operations\n",
    "\n",
    "Descriptor calculators are already prepared actions that you can use with the `addDescriptors` method. However, you can also run custom operations on the data set in parallel. To do this, you need to use the `apply` method. This method takes a function as input and runs it on each chunk of the data set in parallel. The function must take a dictionary of properties as input and return anything as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d222001afae4d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.082418114Z",
     "start_time": "2024-01-16T16:31:10.077838705Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object PandasDataTable.apply at 0x7f4ad2fa7530>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processing_function(props: dict, *args, **kwargs):\n",
    "    \"\"\"A simple function to process a chunk of a data table. Just prints and its arguments.\"\"\"\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "    for prop in props:\n",
    "        print(prop, props[prop][0])\n",
    "\n",
    "\n",
    "mt.nJobs = 2  # also resets the chunk size to 50% of the data set size again\n",
    "mt.apply(processing_function, func_args=(\"A\",), func_kwargs={\"B\": None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada92396624b990",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, this gives us a generator object. In order to run the function on each chunk and get the results, we need to iterate over the generator and collect results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f2cf1850ecf7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.175831497Z",
     "start_time": "2024-01-16T16:31:10.081098696Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A',)\n",
      "('A',){'B': None}\n",
      "\n",
      "{'B': None}SMILES\n",
      " SMILESBrc1cc(Nc2nc3c(ncnc3N3CCCC3)s2)ccc1 \n",
      "COc1cc(-n2c(=O)n(-c3c(OC)cccc3)c3c2nc(NC2CC2)nc3)ccc1P0DMS8\n",
      " P0DMS85.89 \n",
      "nanP29274\n",
      " P292746.61\n",
      " P292755.29 \n",
      "nanP29275\n",
      "P30542  nannan\n",
      "\n",
      "P30542QSPRID  5.9ParallelizationExample_0000\n",
      "\n",
      "QSPRID \n",
      "ParallelizationExample_3398('A',)\n",
      "{'B': None}\n",
      "SMILES c1nc2c(nc(Nc3ccc(N4CCOCC4)cc3)nc2NC2CCCCCCC2)[nH]1\n",
      "P0DMS8 5.56\n",
      "P29274 nan\n",
      "P29275 nan\n",
      "P30542 nan\n",
      "QSPRID ParallelizationExample_6796\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for result in mt.apply(processing_function, func_args=(\"A\",), func_kwargs={\"B\": None}):\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2d451e08ec155",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The results in this case are just four `None` values since our function doesn't return anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba475bbd0735f20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.223479222Z",
     "start_time": "2024-01-16T16:31:10.180906772Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a590acb0626ee9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also instruct the `apply` method to pass a `DataFrame` instead of a dictionary of properties to the function. This is useful if you want to use the `pandas.DataFrame` API to process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a63acad6cfaa31eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.254595551Z",
     "start_time": "2024-01-16T16:31:10.227714969Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3398, 6), (3398, 6), (1, 6)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processing_function_df(props: pd.DataFrame):\n",
    "    \"\"\"A simple function that gives us the shape of the chunk.\"\"\"\n",
    "    return props.shape\n",
    "\n",
    "\n",
    "results = []\n",
    "for result in mt.apply(processing_function_df, as_df=True):\n",
    "    results.append(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14646b3cc04daee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**WARNING:** The `apply` method does not guarantee that the results will be returned in the same order as the chunks were processed. This is because the chunks are processed in parallel and the order depends on the order in which the parallel processes finish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcfa580de331",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Molecule Processors\n",
    "\n",
    "One step above the simple `apply` method is the `processMols` method. This method takes a `MolProcessor` object as input. This object must implement a `__call__` method that takes a list of molecules and a dictionary of properties as input and returns anything as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f4256b379457379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.307074944Z",
     "start_time": "2024-01-16T16:31:10.228216373Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brc1cc(Nc2nc3c(ncnc3N3CCCC3)s2)ccc1',\n",
       "  str,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " ('COc1cc(-n2c(=O)n(-c3c(OC)cccc3)c3c2nc(NC2CC2)nc3)ccc1',\n",
       "  str,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " ('c1nc2c(nc(Nc3ccc(N4CCOCC4)cc3)nc2NC2CCCCCCC2)[nH]1',\n",
       "  str,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qsprpred.data.processing.mol_processor import MolProcessor\n",
    "from rdkit.Chem import Mol\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class MyProcessor(MolProcessor):\n",
    "    def __call__(self, mols: list[str | Mol], props: dict[str, list[Any]], *args,\n",
    "                 **kwargs) -> Any:\n",
    "        \"\"\"Just return a tuple of some data extracted for the first molecule in the chunk.\"\"\"\n",
    "        return mols[0], type(mols[0]), *props.keys()\n",
    "\n",
    "    @property\n",
    "    def supportsParallel(self) -> bool:\n",
    "        \"\"\"Needs to be set to indicate if parallelization is supported.\"\"\"\n",
    "        return True\n",
    "\n",
    "\n",
    "results = []\n",
    "for result in mt.processMols(MyProcessor()):\n",
    "    results.append(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a679c7ec23c64a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With `processMols`, we can also automatically convert the molecules to RDKit molecules before passing them to the processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf4e78a2249d7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:10.955175012Z",
     "start_time": "2024-01-16T16:31:10.278782050Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<rdkit.Chem.rdchem.Mol at 0x7f4ad2d15c10>,\n",
       "  rdkit.Chem.rdchem.Mol,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " (<rdkit.Chem.rdchem.Mol at 0x7f4ad2d15d00>,\n",
       "  rdkit.Chem.rdchem.Mol,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " (<rdkit.Chem.rdchem.Mol at 0x7f4ad2d14040>,\n",
       "  rdkit.Chem.rdchem.Mol,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for result in mt.processMols(MyProcessor(), as_rdkit=True):\n",
    "    results.append(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927b7b9fe7bfa4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You can also derive from `MolProcessorWithID` if you want to access the molecule IDs provided by the data set in your processor. This is useful to overcome the issue that the order in which chunks are processed is not guaranteed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f0adadb4d33539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T16:31:12.843689806Z",
     "start_time": "2024-01-16T16:31:10.956455648Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QSPRID\n",
       "ParallelizationExample_0000    YQTYPSIBGJUFHX-UHFFFAOYSA-N\n",
       "ParallelizationExample_0001    PLOWTFYCKMBDSF-UHFFFAOYSA-N\n",
       "ParallelizationExample_0002    VPFDYFVHIDPXMF-UHFFFAOYSA-N\n",
       "ParallelizationExample_0003    JRZQBZNLNNVCDD-UHFFFAOYSA-N\n",
       "ParallelizationExample_0004    ZQOOZBCGGHKMAZ-UHFFFAOYSA-N\n",
       "                                          ...             \n",
       "ParallelizationExample_6792    ATQMYSVYZWCLGV-UHFFFAOYSA-N\n",
       "ParallelizationExample_6793    BCUWHWNNRNCIEH-UHFFFAOYSA-N\n",
       "ParallelizationExample_6794    ZFLJHSQHILSNCM-UHFFFAOYSA-N\n",
       "ParallelizationExample_6795    IWDCLHPAOHUVIN-UHFFFAOYSA-N\n",
       "ParallelizationExample_6796    SXZJJBXZKSACII-UHFFFAOYSA-N\n",
       "Name: InchiKey, Length: 6797, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit.Chem import MolToInchiKey\n",
    "from qsprpred.data.processing.mol_processor import MolProcessorWithID\n",
    "\n",
    "\n",
    "class MyProcessorWithID(MolProcessorWithID):\n",
    "    def __call__(self, mols: list[str | Mol], props: dict[str, list[Any]], *args,\n",
    "                 **kwargs) -> Any:\n",
    "        \"\"\"Calculate Inchi Keys for the molecules in the chunk and return them as a DataFrame using `idProp` as index.\"\"\"\n",
    "        return pd.DataFrame({\"InchiKey\": [MolToInchiKey(x) for x in mols]},\n",
    "                            index=props[self.idProp])\n",
    "\n",
    "    @property\n",
    "    def supportsParallel(self) -> bool:\n",
    "        return True\n",
    "\n",
    "\n",
    "# run the calculations\n",
    "results = []\n",
    "for result in mt.processMols(MyProcessorWithID(), as_rdkit=True):\n",
    "    results.append(result)\n",
    "\n",
    "# concatenate the results into a single DataFrame\n",
    "df_iks = pd.concat(results)\n",
    "\n",
    "# sort the DataFrame by the index to ensure same order as in the original molecule table\n",
    "df_iks.sort_index(inplace=True)\n",
    "\n",
    "# set the Inchi Keys as a property of the molecule table\n",
    "mt.addProperty(\"InchiKey\", df_iks.InchiKey.tolist())\n",
    "mt.getProperty(\"InchiKey\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
