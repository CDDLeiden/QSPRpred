{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fedcee856268b35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Code Parallelization\n",
    "\n",
    "QSPRpred is also helpful to run parallel operations on data. It tries to take the headache out of parallelization by\n",
    "providing a simple interface to run operations on data in parallel. In this tutorial, we will show how to use the\n",
    "these features.\n",
    "\n",
    "## Example Data Set\n",
    "\n",
    "We will borrow the multitask data set from the [associated tutorial](../modelling/multi_task_modelling.ipynb) since it contains a larger number of molecules:"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:10.902999Z",
     "start_time": "2024-04-05T09:03:09.331256Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from qsprpred.data import MoleculeTable\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('../../tutorial_data/AR_LIGANDS.tsv', sep='\\t')\n",
    "df = df.pivot(index=\"SMILES\", columns=\"accession\", values=\"pchembl_value_Mean\")\n",
    "df.columns.name = None\n",
    "df.reset_index(inplace=True)\n",
    "mt = MoleculeTable(name=\"ParallelizationExample\", df=df)\n",
    "len(mt)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2599323/3081504600.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6797"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8f9ffda3a4b8202f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setting `nJobs` and `chunkSize`\n",
    "\n",
    "QSPRpred supports parallelization of code by chunking the data set into smaller\n",
    "pieces and running the code on each chunk in parallel. This is done by setting\n",
    "the `nJobs` and `chunkSize` properties of the `MoleculeTable` object. The\n",
    "`nJobs` property specifies the number of parallel jobs to run. The `chunkSize`\n",
    "property specifies the number of molecules to process in each job. \n",
    "\n",
    "The `chunkSize` property is automatically calculated based on the number of jobs, but\n",
    "in some cases it may be useful to set it manually. For example, if the code\n",
    "being run in parallel is very fast, it may be useful to increase the chunk size\n",
    "to reduce the overhead of parallelization. On the other hand, if the code being\n",
    "run in parallel is very slow, it may be useful to decrease the chunk size to\n",
    "reduce the amount of time spent waiting for the slowest job to finish. \n",
    "\n",
    "In addition, the\n",
    "`chunkSize` property also affects the memory usage of the parallelization. If\n",
    "the code being run in parallel is very memory intensive, it may be useful to\n",
    "decrease the chunk size to reduce the memory usage of the parallel processes \n",
    "by running on smaller batches of data.\n",
    "\n",
    "We will now illustrate a few different scenarios. First, we will run a simple\n",
    "descriptor calculation in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5fb8189f4bd2cf62",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:14.098308Z",
     "start_time": "2024-04-05T09:03:10.904430Z"
    }
   },
   "source": [
    "from qsprpred.data.descriptors.sets import DescriptorSet\n",
    "from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "from qsprpred.utils.stopwatch import StopWatch\n",
    "\n",
    "\n",
    "def time_desc_calc(data: MoleculeTable, desc_set: DescriptorSet):\n",
    "    \"\"\"A simple function to time descriptor calculation on a data table.\n",
    "    \n",
    "    Args:\n",
    "        data: The data table to calculate descriptors on.\n",
    "        desc_set: The descriptor set to calculate.\n",
    "    \"\"\"\n",
    "    if data.hasDescriptors([desc_set])[0]:\n",
    "        print(f\"Removing old descriptors: {desc_set}\")\n",
    "        data.dropDescriptorSets([desc_set], full_removal=True)\n",
    "    print(f\"Running and timing descriptor calculation: {desc_set}\")\n",
    "    watch = StopWatch()\n",
    "    data.addDescriptors([desc_set])\n",
    "    watch.stop()\n",
    "\n",
    "\n",
    "time_desc_calc(mt, MorganFP(3, 2048))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running and timing descriptor calculation: MorganFP\n",
      "Time it took: 3.1895658829889726\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9357f12c0516b989",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This calculation is done on one CPU by default:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e44f3b39aa13bde1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:14.101750Z",
     "start_time": "2024-04-05T09:03:14.099062Z"
    }
   },
   "source": [
    "mt.nJobs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "e7e51a9829413df0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and the whole data set supplied as one chunk:"
   ]
  },
  {
   "cell_type": "code",
   "id": "79a597d9ec3e477d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:14.116742Z",
     "start_time": "2024-04-05T09:03:14.102388Z"
    }
   },
   "source": [
    "mt.chunkSize"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6797"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "d28c75dc19273bed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can now try running this calculation in parallel on 2 CPUs:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b6a15d314e606079",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:14.123087Z",
     "start_time": "2024-04-05T09:03:14.118057Z"
    }
   },
   "source": [
    "mt.nJobs = 4"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "6bc6ee9045cc5f12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The chunk size will automatically be adjusted to 25% of the data set size so that each portion of the data set is processed on a separate CPU:"
   ]
  },
  {
   "cell_type": "code",
   "id": "8de8694100c644d5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:14.126111Z",
     "start_time": "2024-04-05T09:03:14.123767Z"
    }
   },
   "source": [
    "mt.chunkSize"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "2e21998b62ee78bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see how this affects the time taken to run the calculation:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a99a9131bc8db3e4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:15.142388Z",
     "start_time": "2024-04-05T09:03:14.126729Z"
    }
   },
   "source": [
    "time_desc_calc(mt, MorganFP(3, 2048))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old descriptors: MorganFP\n",
      "Running and timing descriptor calculation: MorganFP\n",
      "Time it took: 1.0002258270105813\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "bc5243c149010a23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This was faster, but not by a factor of 4. This is because there is some overhead associated with parallelization and the calculation of fingerprints is very fast by itself so the overhead affects our runtime more. In such cases, be careful about setting the chunk size manually:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d5b1bdf9bdb5db6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:20.989466Z",
     "start_time": "2024-04-05T09:03:15.143496Z"
    }
   },
   "source": [
    "mt.chunkSize = 10\n",
    "time_desc_calc(mt, MorganFP(3, 2048))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old descriptors: MorganFP\n",
      "Running and timing descriptor calculation: MorganFP\n",
      "Time it took: 5.829503027023748\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "c9fdc32aa83072e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This was slower than even the single CPU calculation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2367dd655da9c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Custom Operations\n",
    "\n",
    "Descriptor calculators are already prepared actions that you can use with the `addDescriptors` method. However, you can also run custom operations on the data set in parallel. To do this, you need to use the `apply` method. This method takes a function as input and runs it on each chunk of the data set in parallel. The function must take a dictionary of properties as input and return anything as output:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d222001afae4d0b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:20.993551Z",
     "start_time": "2024-04-05T09:03:20.990410Z"
    }
   },
   "source": [
    "def processing_function(props: dict, *args, **kwargs):\n",
    "    \"\"\"A simple function to process a chunk of a data table. Just prints and its arguments.\"\"\"\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "    for prop in props:\n",
    "        print(prop, props[prop][0])\n",
    "\n",
    "\n",
    "mt.nJobs = 2  # also resets the chunk size to 50% of the data set size again\n",
    "mt.apply(processing_function, func_args=(\"A\",), func_kwargs={\"B\": None})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object PandasDataTable.apply at 0x7f4fdb0d0350>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "3ada92396624b990",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, this gives us a generator object. In order to run the function on each chunk and get the results, we need to iterate over the generator and collect results:"
   ]
  },
  {
   "cell_type": "code",
   "id": "99f2cf1850ecf7cc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:21.071951Z",
     "start_time": "2024-04-05T09:03:20.994221Z"
    }
   },
   "source": [
    "results = []\n",
    "for result in mt.apply(processing_function, func_args=(\"A\",), func_kwargs={\"B\": None}):\n",
    "    results.append(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A',)('A',)\n",
      "{'B': None}\n",
      "\n",
      "SMILES{'B': None}\n",
      " Brc1cc(Nc2nc3c(ncnc3N3CCCC3)s2)ccc1SMILES\n",
      " P0DMS8COc1cc(-n2c(=O)n(-c3c(OC)cccc3)c3c2nc(NC2CC2)nc3)ccc1\n",
      " P0DMS85.89 \n",
      "nanP29274\n",
      "P29274  6.615.29\n",
      "\n",
      "P29275P29275  nannan\n",
      "P30542\n",
      " P305425.9 \n",
      "nanQSPRID\n",
      " QSPRIDParallelizationExample_3398 \n",
      "ParallelizationExample_0000\n",
      "('A',)\n",
      "{'B': None}\n",
      "SMILES c1nc2c(nc(Nc3ccc(N4CCOCC4)cc3)nc2NC2CCCCCCC2)[nH]1\n",
      "P0DMS8 5.56\n",
      "P29274 nan\n",
      "P29275 nan\n",
      "P30542 nan\n",
      "QSPRID ParallelizationExample_6796\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "a5f2d451e08ec155",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The results in this case are just four `None` values since our function doesn't return anything:"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ba475bbd0735f20",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:21.075501Z",
     "start_time": "2024-04-05T09:03:21.072880Z"
    }
   },
   "source": [
    "results"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "84a590acb0626ee9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also instruct the `apply` method to pass a `DataFrame` instead of a dictionary of properties to the function. This is useful if you want to use the `pandas.DataFrame` API to process the data:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a63acad6cfaa31eb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:21.118532Z",
     "start_time": "2024-04-05T09:03:21.076071Z"
    }
   },
   "source": [
    "def processing_function_df(props: pd.DataFrame):\n",
    "    \"\"\"A simple function that gives us the shape of the chunk.\"\"\"\n",
    "    return props.shape\n",
    "\n",
    "\n",
    "results = []\n",
    "for result in mt.apply(processing_function_df, as_df=True):\n",
    "    results.append(result)\n",
    "results"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3398, 6), (3398, 6), (1, 6)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "a14646b3cc04daee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**WARNING:** The `apply` method does not guarantee that the results will be returned in the same order as the chunks were processed. This is because the chunks are processed in parallel and the order depends on the order in which the parallel processes finish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcfa580de331",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Molecule Processors\n",
    "\n",
    "One step above the simple `apply` method is the `processMols` method. This method takes a `MolProcessor` object as input. This object must implement a `__call__` method that takes a list of molecules and a dictionary of properties as input and returns anything as output:"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f4256b379457379",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:21.168253Z",
     "start_time": "2024-04-05T09:03:21.119619Z"
    }
   },
   "source": [
    "from qsprpred.data.processing.mol_processor import MolProcessor\n",
    "from rdkit.Chem import Mol\n",
    "from typing import Any, Generator, Callable\n",
    "\n",
    "\n",
    "class MyProcessor(MolProcessor):\n",
    "    def __call__(self, mols: list[str | Mol], props: dict[str, list[Any]], *args,\n",
    "                 **kwargs) -> Any:\n",
    "        \"\"\"Just return a tuple of some data extracted for the first molecule in the chunk.\"\"\"\n",
    "        return mols[0], type(mols[0]), *props.keys()\n",
    "\n",
    "    @property\n",
    "    def supportsParallel(self) -> bool:\n",
    "        \"\"\"Needs to be set to indicate if parallelization is supported.\"\"\"\n",
    "        return True\n",
    "\n",
    "\n",
    "results = []\n",
    "for result in mt.processMols(MyProcessor()):\n",
    "    results.append(result)\n",
    "results"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brc1cc(Nc2nc3c(ncnc3N3CCCC3)s2)ccc1',\n",
       "  str,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " ('COc1cc(-n2c(=O)n(-c3c(OC)cccc3)c3c2nc(NC2CC2)nc3)ccc1',\n",
       "  str,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " ('c1nc2c(nc(Nc3ccc(N4CCOCC4)cc3)nc2NC2CCCCCCC2)[nH]1',\n",
       "  str,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "d4a679c7ec23c64a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With `processMols`, we can also automatically convert the molecules to RDKit molecules before passing them to the processor:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4cf4e78a2249d7c9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:21.585993Z",
     "start_time": "2024-04-05T09:03:21.170430Z"
    }
   },
   "source": [
    "results = []\n",
    "for result in mt.processMols(MyProcessor(), as_rdkit=True):\n",
    "    results.append(result)\n",
    "results"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<rdkit.Chem.rdchem.Mol at 0x7f4fdb0a7560>,\n",
       "  rdkit.Chem.rdchem.Mol,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " (<rdkit.Chem.rdchem.Mol at 0x7f4fdb0a7650>,\n",
       "  rdkit.Chem.rdchem.Mol,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID'),\n",
       " (<rdkit.Chem.rdchem.Mol at 0x7f4fdb0a7380>,\n",
       "  rdkit.Chem.rdchem.Mol,\n",
       "  'SMILES',\n",
       "  'P0DMS8',\n",
       "  'P29274',\n",
       "  'P29275',\n",
       "  'P30542',\n",
       "  'QSPRID')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "4927b7b9fe7bfa4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You can also derive from `MolProcessorWithID` if you want to access the molecule IDs provided by the data set in your processor. This is useful to overcome the issue that the order in which chunks are processed is not guaranteed:"
   ]
  },
  {
   "cell_type": "code",
   "id": "68f0adadb4d33539",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:22.725087Z",
     "start_time": "2024-04-05T09:03:21.587003Z"
    }
   },
   "source": [
    "from rdkit.Chem import MolToInchiKey\n",
    "from qsprpred.data.processing.mol_processor import MolProcessorWithID\n",
    "\n",
    "\n",
    "class MyProcessorWithID(MolProcessorWithID):\n",
    "    def __call__(self, mols: list[str | Mol], props: dict[str, list[Any]], *args,\n",
    "                 **kwargs) -> Any:\n",
    "        \"\"\"Calculate Inchi Keys for the molecules in the chunk and return them as a DataFrame using `idProp` as index.\"\"\"\n",
    "        return pd.DataFrame({\"InchiKey\": [MolToInchiKey(x) for x in mols]},\n",
    "                            index=props[self.idProp])\n",
    "\n",
    "    @property\n",
    "    def supportsParallel(self) -> bool:\n",
    "        return True\n",
    "\n",
    "\n",
    "# run the calculations\n",
    "results = []\n",
    "for result in mt.processMols(MyProcessorWithID(), as_rdkit=True):\n",
    "    results.append(result)\n",
    "\n",
    "# concatenate the results into a single DataFrame\n",
    "df_iks = pd.concat(results)\n",
    "\n",
    "# sort the DataFrame by the index to ensure same order as in the original molecule table\n",
    "df_iks.sort_index(inplace=True)\n",
    "\n",
    "# set the Inchi Keys as a property of the molecule table\n",
    "mt.addProperty(\"InchiKey\", df_iks.InchiKey.tolist())\n",
    "mt.getProperty(\"InchiKey\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QSPRID\n",
       "ParallelizationExample_0000    YQTYPSIBGJUFHX-UHFFFAOYSA-N\n",
       "ParallelizationExample_0001    PLOWTFYCKMBDSF-UHFFFAOYSA-N\n",
       "ParallelizationExample_0002    VPFDYFVHIDPXMF-UHFFFAOYSA-N\n",
       "ParallelizationExample_0003    JRZQBZNLNNVCDD-UHFFFAOYSA-N\n",
       "ParallelizationExample_0004    ZQOOZBCGGHKMAZ-UHFFFAOYSA-N\n",
       "                                          ...             \n",
       "ParallelizationExample_6792    ATQMYSVYZWCLGV-UHFFFAOYSA-N\n",
       "ParallelizationExample_6793    BCUWHWNNRNCIEH-UHFFFAOYSA-N\n",
       "ParallelizationExample_6794    ZFLJHSQHILSNCM-UHFFFAOYSA-N\n",
       "ParallelizationExample_6795    IWDCLHPAOHUVIN-UHFFFAOYSA-N\n",
       "ParallelizationExample_6796    SXZJJBXZKSACII-UHFFFAOYSA-N\n",
       "Name: InchiKey, Length: 6797, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Changing the Parallelization Backend\n",
    "\n",
    "Parallelization of data set operations is handled by the `parallelGenerator` of the `MoleculeTable` object. By default, the `MultiprocessingJITGenerator` is used. This generator uses the `multiprocessing` module to run the operations in parallel on the chunks provided as a generator by the `MoleculeTable`. However, you can also use any other implementation of the `ParallelGenerator` interface and replace the default generator with it. For example, you can use the `DaskJITGenerator` to run the operations above just the same, but this time with Dask as the parallel backend:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89077025bba8e158"
  },
  {
   "cell_type": "code",
   "source": [
    "from qsprpred.extra.utils.parallel import DaskJITGenerator\n",
    "\n",
    "mt.parallelGenerator = DaskJITGenerator(mt.nJobs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:22.871308Z",
     "start_time": "2024-04-05T09:03:22.726306Z"
    }
   },
   "id": "79bd0d65ee6e26c0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "results = []\n",
    "for result in mt.processMols(MyProcessorWithID(), as_rdkit=True):\n",
    "    results.append(result)\n",
    "df_iks = pd.concat(results)\n",
    "df_iks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:25.527774Z",
     "start_time": "2024-04-05T09:03:22.872091Z"
    }
   },
   "id": "40308c3dcd870196",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n",
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                InchiKey\n",
       "ParallelizationExample_3398  UIPGYPFXNHMJOO-UHFFFAOYSA-N\n",
       "ParallelizationExample_3399  YVTRRGUYCMDLRM-UHFFFAOYSA-N\n",
       "ParallelizationExample_3400  AJRRIEGYRSNLNQ-UHFFFAOYSA-N\n",
       "ParallelizationExample_3401  NKRRZFOQPKVEPI-UHFFFAOYSA-N\n",
       "ParallelizationExample_3402  DJEOUFPKQANXEL-UHFFFAOYSA-N\n",
       "...                                                  ...\n",
       "ParallelizationExample_3394  MZTFCUSRGDDALU-UHFFFAOYSA-N\n",
       "ParallelizationExample_3395  SVMXCMXOKKBEET-UHFFFAOYSA-N\n",
       "ParallelizationExample_3396  VUNGHUKQQDSODO-UHFFFAOYSA-N\n",
       "ParallelizationExample_3397  UDUDPDCSVFAFFL-UHFFFAOYSA-N\n",
       "ParallelizationExample_6796  SXZJJBXZKSACII-UHFFFAOYSA-N\n",
       "\n",
       "[6797 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InchiKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3398</th>\n",
       "      <td>UIPGYPFXNHMJOO-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3399</th>\n",
       "      <td>YVTRRGUYCMDLRM-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3400</th>\n",
       "      <td>AJRRIEGYRSNLNQ-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3401</th>\n",
       "      <td>NKRRZFOQPKVEPI-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3402</th>\n",
       "      <td>DJEOUFPKQANXEL-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3394</th>\n",
       "      <td>MZTFCUSRGDDALU-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3395</th>\n",
       "      <td>SVMXCMXOKKBEET-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3396</th>\n",
       "      <td>VUNGHUKQQDSODO-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_3397</th>\n",
       "      <td>UDUDPDCSVFAFFL-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_6796</th>\n",
       "      <td>SXZJJBXZKSACII-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6797 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": "By default, the `DaskJITGenerator` will use an automatically initialized local Dask cluster to run the operations in parallel. However, you can also customize the client so that it uses SSH to connect to a remote Dask cluster. You could for example deploy an SSH Dask cluster and then use it in your client by overriding the `getPool` method. You can uncomment the following cells to try a simple example on your local machine (see the `DaskJITGenerator` and `SSHCluster` documentation for more information):",
   "metadata": {
    "collapsed": false
   },
   "id": "337560db009f1c56"
  },
  {
   "cell_type": "code",
   "source": "# !pip install asyncssh bokeh==2.4.3 # dependencies for the dashboard and SSHCluster",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:25.530268Z",
     "start_time": "2024-04-05T09:03:25.528560Z"
    }
   },
   "id": "629709641dda0511",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# from dask.distributed import SSHCluster\n",
    "# \n",
    "# cluster = SSHCluster(\n",
    "#     [\"localhost\", \"localhost\"], # first argument is the scheduler, the rest are workers (just one in this case)\n",
    "#     connect_options={\"known_hosts\": None},\n",
    "#     worker_options={\"nthreads\": 1, \"n_workers\": mt.nJobs},\n",
    "#     scheduler_options={\"port\": 0, \"dashboard_address\": \":8797\"}, # dashboard will be available at http://localhost:8797/status\n",
    "# )\n",
    "# cluster"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:25.546401Z",
     "start_time": "2024-04-05T09:03:25.530836Z"
    }
   },
   "id": "4e94ca2ac3a15eb8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "# from dask.distributed import Client\n",
    "# \n",
    "# \n",
    "# class CustomDaskJITGenerator(DaskJITGenerator):\n",
    "#     \"\"\"A custom Dask JIT generator that uses a custom Dask client.\"\"\"\n",
    "# \n",
    "#     def getPool(self):\n",
    "#         \"\"\"Get a Dask client that connects to our custom cluster set up above.\"\"\"\n",
    "#         return Client(cluster)\n",
    "# \n",
    "# \n",
    "# mt.parallelGenerator = CustomDaskJITGenerator(mt.nJobs)\n",
    "# \n",
    "# results = []\n",
    "# for result in mt.processMols(MyProcessorWithID(), as_rdkit=True):\n",
    "#     results.append(result)\n",
    "# df_iks = pd.concat(results)\n",
    "# df_iks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:25.553377Z",
     "start_time": "2024-04-05T09:03:25.546940Z"
    }
   },
   "id": "6cf6054c6b4ea4c6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "# undeploy the cluster\n",
    "# cluster.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:25.555319Z",
     "start_time": "2024-04-05T09:03:25.553911Z"
    }
   },
   "id": "96856db1b2790b3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note:** The JIT abbreviation stands for \"Just In Time\" and reflects the fact that all classes deriving from the `JITParallelGenerator` interface evaluate the input generator item by item according to the number of available workers. This is useful to keep the memory usage low for potentially large data sets when running multiprocessing. However, you could implement any kind of parallelization strategy by deriving from the `ParallelGenerator` interface directly: ",
   "id": "b7238041d5358d01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:27.713740Z",
     "start_time": "2024-04-05T09:03:25.556075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qsprpred.utils.parallel import ParallelGenerator\n",
    "\n",
    "\n",
    "class JoblibGenerator(ParallelGenerator):\n",
    "    \"\"\"Example of a custom parallel generator with progress bar and using the joblib library.\"\"\"\n",
    "\n",
    "    def __init__(self, nJobs: int):\n",
    "        self.nJobs = nJobs\n",
    "\n",
    "    def make(self, generator: Generator, process_func: Callable, *args,\n",
    "             **kwargs) -> Generator:\n",
    "        \"\"\"Run the process function on the generator in parallel.\"\"\"\n",
    "        from tqdm import tqdm\n",
    "        from joblib import Parallel, delayed\n",
    "\n",
    "        # get the number of items in the generator\n",
    "        generated_list = list(generator)\n",
    "\n",
    "        # run the process function in parallel\n",
    "        for result in Parallel(n_jobs=self.nJobs)(\n",
    "                delayed(process_func)(item, *args, **kwargs) for item in\n",
    "                tqdm(generated_list)\n",
    "        ):\n",
    "            yield result\n",
    "\n",
    "\n",
    "mt.parallelGenerator = JoblibGenerator(mt.nJobs)\n",
    "mt.chunkSize = 10  # reduce the chunk size to showcase the progress bar a bit better :)\n",
    "results = []\n",
    "for result in mt.processMols(MyProcessorWithID(), as_rdkit=True):\n",
    "    results.append(result)\n",
    "\n",
    "df_iks = pd.concat(results)\n",
    "df_iks"
   ],
   "id": "a6d98a17179270d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/680 [00:00<?, ?it/s]Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n",
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n",
      "100%|██████████| 680/680 [00:01<00:00, 457.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                InchiKey\n",
       "ParallelizationExample_0000  YQTYPSIBGJUFHX-UHFFFAOYSA-N\n",
       "ParallelizationExample_0001  PLOWTFYCKMBDSF-UHFFFAOYSA-N\n",
       "ParallelizationExample_0002  VPFDYFVHIDPXMF-UHFFFAOYSA-N\n",
       "ParallelizationExample_0003  JRZQBZNLNNVCDD-UHFFFAOYSA-N\n",
       "ParallelizationExample_0004  ZQOOZBCGGHKMAZ-UHFFFAOYSA-N\n",
       "...                                                  ...\n",
       "ParallelizationExample_6792  ATQMYSVYZWCLGV-UHFFFAOYSA-N\n",
       "ParallelizationExample_6793  BCUWHWNNRNCIEH-UHFFFAOYSA-N\n",
       "ParallelizationExample_6794  ZFLJHSQHILSNCM-UHFFFAOYSA-N\n",
       "ParallelizationExample_6795  IWDCLHPAOHUVIN-UHFFFAOYSA-N\n",
       "ParallelizationExample_6796  SXZJJBXZKSACII-UHFFFAOYSA-N\n",
       "\n",
       "[6797 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InchiKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_0000</th>\n",
       "      <td>YQTYPSIBGJUFHX-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_0001</th>\n",
       "      <td>PLOWTFYCKMBDSF-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_0002</th>\n",
       "      <td>VPFDYFVHIDPXMF-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_0003</th>\n",
       "      <td>JRZQBZNLNNVCDD-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_0004</th>\n",
       "      <td>ZQOOZBCGGHKMAZ-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_6792</th>\n",
       "      <td>ATQMYSVYZWCLGV-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_6793</th>\n",
       "      <td>BCUWHWNNRNCIEH-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_6794</th>\n",
       "      <td>ZFLJHSQHILSNCM-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_6795</th>\n",
       "      <td>IWDCLHPAOHUVIN-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParallelizationExample_6796</th>\n",
       "      <td>SXZJJBXZKSACII-UHFFFAOYSA-N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6797 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T09:03:27.716132Z",
     "start_time": "2024-04-05T09:03:27.714446Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2e197de5b63eb1c3",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
